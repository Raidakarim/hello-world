{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q4_wide_narrow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXFuRiis35Z+KHIIqB2ql1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raidakarim/hello-world/blob/master/q4_wide_narrow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Eio4ddUPrg0r",
        "outputId": "a2a3f79b-35df-48e5-a9b1-c4bb38e9803a"
      },
      "source": [
        "'''\n",
        "CSE 446 Winter 2021\n",
        "Homework 3\n",
        "Question 4\n",
        "Neural Networks for MNIST\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)\n",
        "\n",
        "# get data from torchvision, transform into tensor, wrap in iterable dataloader\n",
        "to_tensor = transforms.ToTensor()\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, \n",
        "                                transform=to_tensor)\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, \n",
        "                               transform=to_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset,batch_size=128, \n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset,batch_size=128, \n",
        "                                          shuffle=True)\n",
        "\n",
        "# torch.matmul gives (Matrix product of two tensors)\n",
        "# define networks with given forward pass equations\n",
        "\n",
        "def wide_and_shallow_network(x, W0, W1, b0, b1):\n",
        "  layer1 = torch.matmul(x, W0.T) + b0\n",
        "  return torch.matmul(nn.functional.relu(layer1), W1.T) + b1\n",
        "  \n",
        "\n",
        "def narrow_and_deep_network(x, W0, W1, W2, b0, b1, b2):\n",
        "  layer1 = torch.matmul(x, W0.T) + b0\n",
        "  layer2 = torch.matmul(nn.functional.relu(layer1), W1.T) + b1\n",
        "  return torch.matmul(nn.functional.relu(layer2), W2.T) + b2\n",
        "\n",
        "'''\n",
        "Train neural networks:\n",
        "If U is a random variable uniformly distributed on [0, 1],\n",
        "(r1 - r2) * U + r2 is uniformly distributed on [r1, r2].\n",
        "So, for Unif(- alpha, alpha), we get:\n",
        "(- alpha - alpha) * W or b + alpha = -2 * alpha * W or b + alpha\n",
        "'''\n",
        "def train_wide_and_shallow_network(data_loader, l, num_epochs, h = 64, n = 784, \n",
        "                                   k = 10):\n",
        "  # initialize weights and biases randomly\n",
        "  alpha = 1/np.sqrt(n)\n",
        "  W0 = -2*alpha* torch.rand(h, n) + alpha\n",
        "  W0.requires_grad = True\n",
        "  W1 = -2*alpha* torch.rand(k, h) + alpha\n",
        "  W1.requires_grad = True\n",
        "  b0 = -2*alpha* torch.rand(h) + alpha\n",
        "  b0.requires_grad = True\n",
        "  b1 = -2*alpha* torch.rand(k) + alpha\n",
        "  b1.requires_grad = True\n",
        "\n",
        "  params = [W0, W1, b0, b1]  \n",
        "  # optimization function\n",
        "  optimizer = torch.optim.Adam(params, lr=l) \n",
        "  loss_array = []\n",
        "  for epoch in range(num_epochs):\n",
        "    accuracy = 0\n",
        "    loss_array.append(0)\n",
        "    # iterate through batches\n",
        "    for inputs, labels in tqdm(iter(data_loader)):\n",
        "      # flatten images\n",
        "      inputs = torch.flatten(inputs, start_dim=1, end_dim=3)\n",
        "      # compute predictions to feed as 784 vector elements\n",
        "      forward_pass = wide_and_shallow_network(inputs, W0, W1, b0, b1)\n",
        "      preds = torch.argmax(forward_pass, dim=1)\n",
        "      accuracy += torch.sum(preds == labels)\n",
        "      # compute loss\n",
        "      loss = torch.nn.functional.cross_entropy(forward_pass, labels, \n",
        "                                               size_average = False)\n",
        "      # computes derivatives of the loss with respect to W\n",
        "      optimizer.zero_grad() # set gradients to zero before backpropagation\n",
        "      loss.backward() # backpropagation-- sum of gradients\n",
        "      optimizer.step() # gradient descent- optimizer iterates to update tensors\n",
        "      loss_array[epoch] += loss\n",
        "    loss_array[epoch] = loss_array[epoch]/len(data_loader.dataset)\n",
        "    print(\"For epoch %s training loss is %s\" % (epoch, loss_array[epoch]))\n",
        "    accuracy = accuracy.to(dtype=torch.float)/len(data_loader.dataset)\n",
        "    print(\"For epoch %s training accuracy is %s\" % (epoch, accuracy))\n",
        "    if accuracy > 0.99:\n",
        "      return loss_array, W0, W1, b0, b1\n",
        "  return loss_array, W0, W1, b0, b1\n",
        "\n",
        "\n",
        "def train_narrow_and_deep_network(data_loader, l, num_epochs, h = 32, \n",
        "                                  n = 784, k = 10):\n",
        "  # initialize weights and biases randomly\n",
        "  alpha = 1/np.sqrt(n)\n",
        "  W0 = -2*alpha* torch.rand(h, n) + alpha\n",
        "  W0.requires_grad = True\n",
        "  W1 = -2*alpha* torch.rand(h, h) + alpha\n",
        "  W1.requires_grad = True\n",
        "  W2 = -2*alpha* torch.rand(k, h) + alpha\n",
        "  W2.requires_grad = True\n",
        "  b0 = -2*alpha* torch.rand(h) + alpha\n",
        "  b0.requires_grad = True\n",
        "  b1 = -2*alpha* torch.rand(h) + alpha\n",
        "  b1.requires_grad = True\n",
        "  b2 = -2*alpha* torch.rand(k) + alpha\n",
        "  b2.requires_grad = True\n",
        "  \n",
        "  # optimization function\n",
        "  params = [W0, W1, W2, b0, b1, b2]\n",
        "  optimizer = torch.optim.Adam(params, lr=l)\n",
        "  loss_array = []\n",
        "  for epoch in range(num_epochs):\n",
        "    accuracy = 0\n",
        "    loss_array.append(0)\n",
        "    # iterate through batches\n",
        "    for inputs, labels in tqdm(iter(data_loader)):\n",
        "      # flatten images\n",
        "      inputs = torch.flatten(inputs, start_dim=1, end_dim=3)\n",
        "      # compute predictions\n",
        "      forward_pass = narrow_and_deep_network(inputs, W0, W1, W2, b0, b1, b2)\n",
        "      preds = torch.argmax(forward_pass, dim=1)\n",
        "      accuracy += torch.sum(preds == labels)\n",
        "      # compute loss\n",
        "      loss = torch.nn.functional.cross_entropy(forward_pass, labels, \n",
        "                                               size_average = False)\n",
        "      # computes derivatives of the loss with respect to W\n",
        "      optimizer.zero_grad() # set gradients to zero before backpropagation\n",
        "      loss.backward() # backpropagation-- sum of gradients\n",
        "      optimizer.step() # gradient descent-- optimizer iterates to update tensors\n",
        "      loss_array[epoch] += loss\n",
        "    loss_array[epoch] = loss_array[epoch]/len(data_loader.dataset)\n",
        "    print(\"For epoch %s training loss is %s\" % (epoch, loss_array[epoch]))\n",
        "    accuracy = accuracy.to(dtype=torch.float)/len(data_loader.dataset)\n",
        "    print(\"For epoch %s training accuracy is %s\" % (epoch, accuracy))\n",
        "    if accuracy > 0.99:\n",
        "      return loss_array, W0, W1, W2, b0, b1, b2\n",
        "  return loss_array, W0, W1, W2, b0, b1, b2\n",
        "\n",
        "def test_model(test_loader, network, W0=None, W1=None, W2=None, b0=None, \n",
        "               b1=None, b2=None):\n",
        "  accuracy = 0\n",
        "  loss = 0\n",
        "  for inputs, labels in tqdm(iter(test_loader)):\n",
        "    inputs = torch.flatten(inputs, start_dim=1, end_dim=3)\n",
        "    if network == 'wide':\n",
        "      forward_pass = wide_and_shallow_network(inputs, W0, W1, b0, b1)\n",
        "      preds = torch.argmax(forward_pass, dim=1)\n",
        "    else:\n",
        "      forward_pass = narrow_and_deep_network(inputs, W0, W1, W2, b0, b1, b2)\n",
        "      preds = torch.argmax(forward_pass, dim=1)\n",
        "    accuracy += torch.sum(preds == labels)\n",
        "    loss += torch.nn.functional.cross_entropy(forward_pass, labels, \n",
        "                                              size_average = False)\n",
        "  loss = loss/len(test_loader.dataset)\n",
        "  accuracy = accuracy.to(dtype=torch.float)/len(test_loader.dataset)\n",
        "  return accuracy, loss\n",
        "\n",
        "#Wide and shallow network:\n",
        "loss_array_wide, W0, W1, b0, b1 = train_wide_and_shallow_network(train_loader,\n",
        "                                    0.001, 500, h = 64, n = 784, k = 10)\n",
        "test_acc, test_loss = test_model(test_loader, network ='wide', W0=W0, \n",
        "                                         W1=W1, W2=None, b0=b0, b1=b1, b2=None)\n",
        "print('Test accuracy for wide and shallow network is', test_acc)\n",
        "print('Test loss for wide and shallow network is', test_loss)\n",
        "\n",
        "wide_parameters = np.prod(W0.shape) + np.prod(W1.shape) + np.prod(b0.shape) \n",
        "+ np.prod(b1.shape)\n",
        "print('Number of parameters for wide and shallow network', wide_parameters)\n",
        "\n",
        "#Plot the results\n",
        "plt.plot(range(len(loss_array_wide)), loss_array_wide, '-o')\n",
        "plt.title('Training loss vs. epoch for wide and shallow network')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Deep and narrow network:\n",
        "loss_array_deep, W0, W1, W2, b0, b1, b2 = train_narrow_and_deep_network(\n",
        "                                          train_loader, 0.001, 500, h = 32, \n",
        "                                          n = 784, k = 10)\n",
        "test_acc, test_loss = test_model(test_loader, network ='deep', W0=W0, \n",
        "                                 W1=W1, W2=W2, b0=b0, b1=b1, b2=b2)\n",
        "print('Test accuracy for narrow and deep network is', test_acc)\n",
        "print('Test loss for narrow and deep network is', test_loss)\n",
        "\n",
        "deep_parameters = np.prod(W0.shape) + np.prod(W1.shape) + np.prod(W2.shape) \n",
        "+ np.prod(b0.shape) + np.prod(b1.shape) + np.prod(b2.shape)\n",
        "print('Number of parameters for narrow and deep network', deep_parameters)\n",
        "\n",
        "plt.plot(range(len(loss_array_deep)), loss_array_deep, '-o')\n",
        "plt.title('Training loss vs. epoch for narrow and deep network')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "100%|██████████| 469/469 [00:05<00:00, 93.37it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 93.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 0 training loss is tensor(0.5356, grad_fn=<DivBackward0>)\n",
            "For epoch 0 training accuracy is tensor(0.8618)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.38it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 91.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 1 training loss is tensor(0.2454, grad_fn=<DivBackward0>)\n",
            "For epoch 1 training accuracy is tensor(0.9294)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:05<00:00, 93.77it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 97.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 2 training loss is tensor(0.1900, grad_fn=<DivBackward0>)\n",
            "For epoch 2 training accuracy is tensor(0.9457)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:05<00:00, 93.03it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 94.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 3 training loss is tensor(0.1530, grad_fn=<DivBackward0>)\n",
            "For epoch 3 training accuracy is tensor(0.9561)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:05<00:00, 93.36it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:05, 91.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 4 training loss is tensor(0.1283, grad_fn=<DivBackward0>)\n",
            "For epoch 4 training accuracy is tensor(0.9625)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:05<00:00, 93.23it/s]\n",
            "  2%|▏         | 9/469 [00:00<00:05, 89.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 5 training loss is tensor(0.1100, grad_fn=<DivBackward0>)\n",
            "For epoch 5 training accuracy is tensor(0.9683)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.91it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:05, 91.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 6 training loss is tensor(0.0959, grad_fn=<DivBackward0>)\n",
            "For epoch 6 training accuracy is tensor(0.9720)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.00it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 94.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 7 training loss is tensor(0.0845, grad_fn=<DivBackward0>)\n",
            "For epoch 7 training accuracy is tensor(0.9753)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.75it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 98.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 8 training loss is tensor(0.0758, grad_fn=<DivBackward0>)\n",
            "For epoch 8 training accuracy is tensor(0.9783)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.42it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 91.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 9 training loss is tensor(0.0678, grad_fn=<DivBackward0>)\n",
            "For epoch 9 training accuracy is tensor(0.9807)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.92it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 94.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 10 training loss is tensor(0.0615, grad_fn=<DivBackward0>)\n",
            "For epoch 10 training accuracy is tensor(0.9823)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.99it/s]\n",
            "  2%|▏         | 9/469 [00:00<00:05, 87.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 11 training loss is tensor(0.0550, grad_fn=<DivBackward0>)\n",
            "For epoch 11 training accuracy is tensor(0.9843)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:05<00:00, 93.61it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 97.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 12 training loss is tensor(0.0500, grad_fn=<DivBackward0>)\n",
            "For epoch 12 training accuracy is tensor(0.9858)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:05<00:00, 93.52it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:05, 91.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 13 training loss is tensor(0.0456, grad_fn=<DivBackward0>)\n",
            "For epoch 13 training accuracy is tensor(0.9867)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:05<00:00, 93.25it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 92.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 14 training loss is tensor(0.0417, grad_fn=<DivBackward0>)\n",
            "For epoch 14 training accuracy is tensor(0.9880)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.32it/s]\n",
            "  2%|▏         | 11/469 [00:00<00:04, 101.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 15 training loss is tensor(0.0379, grad_fn=<DivBackward0>)\n",
            "For epoch 15 training accuracy is tensor(0.9893)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.61it/s]\n",
            " 14%|█▍        | 11/79 [00:00<00:00, 103.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 16 training loss is tensor(0.0343, grad_fn=<DivBackward0>)\n",
            "For epoch 16 training accuracy is tensor(0.9906)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:00<00:00, 99.76it/s]\n",
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy for wide and shallow network is tensor(0.9747)\n",
            "Test loss for wide and shallow network is tensor(0.0872, grad_fn=<DivBackward0>)\n",
            "Number of parameters for wide and shallow network 50880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.83it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 94.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 0 training loss is tensor(0.7639, grad_fn=<DivBackward0>)\n",
            "For epoch 0 training accuracy is tensor(0.7599)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.50it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 94.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 1 training loss is tensor(0.3308, grad_fn=<DivBackward0>)\n",
            "For epoch 1 training accuracy is tensor(0.9060)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.84it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 92.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 2 training loss is tensor(0.2681, grad_fn=<DivBackward0>)\n",
            "For epoch 2 training accuracy is tensor(0.9239)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.12it/s]\n",
            "  2%|▏         | 9/469 [00:00<00:05, 86.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 3 training loss is tensor(0.2261, grad_fn=<DivBackward0>)\n",
            "For epoch 3 training accuracy is tensor(0.9358)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.82it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 94.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 4 training loss is tensor(0.1966, grad_fn=<DivBackward0>)\n",
            "For epoch 4 training accuracy is tensor(0.9435)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.82it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 95.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 5 training loss is tensor(0.1736, grad_fn=<DivBackward0>)\n",
            "For epoch 5 training accuracy is tensor(0.9495)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.15it/s]\n",
            "  2%|▏         | 11/469 [00:00<00:04, 101.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 6 training loss is tensor(0.1566, grad_fn=<DivBackward0>)\n",
            "For epoch 6 training accuracy is tensor(0.9536)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.92it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 92.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 7 training loss is tensor(0.1416, grad_fn=<DivBackward0>)\n",
            "For epoch 7 training accuracy is tensor(0.9579)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.10it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 94.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 8 training loss is tensor(0.1305, grad_fn=<DivBackward0>)\n",
            "For epoch 8 training accuracy is tensor(0.9613)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.91it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 93.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 9 training loss is tensor(0.1221, grad_fn=<DivBackward0>)\n",
            "For epoch 9 training accuracy is tensor(0.9633)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.26it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 92.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 10 training loss is tensor(0.1129, grad_fn=<DivBackward0>)\n",
            "For epoch 10 training accuracy is tensor(0.9663)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.12it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 95.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 11 training loss is tensor(0.1064, grad_fn=<DivBackward0>)\n",
            "For epoch 11 training accuracy is tensor(0.9679)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.45it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 96.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 12 training loss is tensor(0.1014, grad_fn=<DivBackward0>)\n",
            "For epoch 12 training accuracy is tensor(0.9692)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.95it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 95.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 13 training loss is tensor(0.0944, grad_fn=<DivBackward0>)\n",
            "For epoch 13 training accuracy is tensor(0.9719)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 97.24it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 96.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 14 training loss is tensor(0.0891, grad_fn=<DivBackward0>)\n",
            "For epoch 14 training accuracy is tensor(0.9728)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.25it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 92.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 15 training loss is tensor(0.0851, grad_fn=<DivBackward0>)\n",
            "For epoch 15 training accuracy is tensor(0.9742)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.96it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 96.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 16 training loss is tensor(0.0818, grad_fn=<DivBackward0>)\n",
            "For epoch 16 training accuracy is tensor(0.9749)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 97.12it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 98.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 17 training loss is tensor(0.0778, grad_fn=<DivBackward0>)\n",
            "For epoch 17 training accuracy is tensor(0.9763)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.90it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 97.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 18 training loss is tensor(0.0744, grad_fn=<DivBackward0>)\n",
            "For epoch 18 training accuracy is tensor(0.9775)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.68it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:05, 91.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 19 training loss is tensor(0.0716, grad_fn=<DivBackward0>)\n",
            "For epoch 19 training accuracy is tensor(0.9781)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.05it/s]\n",
            "  2%|▏         | 9/469 [00:00<00:05, 89.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 20 training loss is tensor(0.0686, grad_fn=<DivBackward0>)\n",
            "For epoch 20 training accuracy is tensor(0.9788)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.01it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 97.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 21 training loss is tensor(0.0668, grad_fn=<DivBackward0>)\n",
            "For epoch 21 training accuracy is tensor(0.9793)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.25it/s]\n",
            "  2%|▏         | 11/469 [00:00<00:04, 101.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 22 training loss is tensor(0.0628, grad_fn=<DivBackward0>)\n",
            "For epoch 22 training accuracy is tensor(0.9804)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.67it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 97.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 23 training loss is tensor(0.0605, grad_fn=<DivBackward0>)\n",
            "For epoch 23 training accuracy is tensor(0.9811)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.29it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 94.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 24 training loss is tensor(0.0583, grad_fn=<DivBackward0>)\n",
            "For epoch 24 training accuracy is tensor(0.9819)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.26it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 96.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 25 training loss is tensor(0.0563, grad_fn=<DivBackward0>)\n",
            "For epoch 25 training accuracy is tensor(0.9826)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.47it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 97.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 26 training loss is tensor(0.0528, grad_fn=<DivBackward0>)\n",
            "For epoch 26 training accuracy is tensor(0.9839)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.59it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 97.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 27 training loss is tensor(0.0511, grad_fn=<DivBackward0>)\n",
            "For epoch 27 training accuracy is tensor(0.9843)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:05<00:00, 93.52it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 94.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 28 training loss is tensor(0.0493, grad_fn=<DivBackward0>)\n",
            "For epoch 28 training accuracy is tensor(0.9845)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 94.91it/s]\n",
            "  2%|▏         | 9/469 [00:00<00:05, 89.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 29 training loss is tensor(0.0478, grad_fn=<DivBackward0>)\n",
            "For epoch 29 training accuracy is tensor(0.9850)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.74it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:05, 90.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 30 training loss is tensor(0.0461, grad_fn=<DivBackward0>)\n",
            "For epoch 30 training accuracy is tensor(0.9852)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 97.03it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 93.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 31 training loss is tensor(0.0442, grad_fn=<DivBackward0>)\n",
            "For epoch 31 training accuracy is tensor(0.9864)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.74it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 98.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 32 training loss is tensor(0.0426, grad_fn=<DivBackward0>)\n",
            "For epoch 32 training accuracy is tensor(0.9867)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.46it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 97.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 33 training loss is tensor(0.0410, grad_fn=<DivBackward0>)\n",
            "For epoch 33 training accuracy is tensor(0.9871)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.86it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 92.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 34 training loss is tensor(0.0391, grad_fn=<DivBackward0>)\n",
            "For epoch 34 training accuracy is tensor(0.9877)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.62it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 96.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 35 training loss is tensor(0.0378, grad_fn=<DivBackward0>)\n",
            "For epoch 35 training accuracy is tensor(0.9877)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 95.23it/s]\n",
            "  2%|▏         | 9/469 [00:00<00:05, 85.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 36 training loss is tensor(0.0359, grad_fn=<DivBackward0>)\n",
            "For epoch 36 training accuracy is tensor(0.9886)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.21it/s]\n",
            "  2%|▏         | 10/469 [00:00<00:04, 96.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 37 training loss is tensor(0.0347, grad_fn=<DivBackward0>)\n",
            "For epoch 37 training accuracy is tensor(0.9890)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 96.24it/s]\n",
            "  2%|▏         | 11/469 [00:00<00:04, 101.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 38 training loss is tensor(0.0332, grad_fn=<DivBackward0>)\n",
            "For epoch 38 training accuracy is tensor(0.9897)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:04<00:00, 97.30it/s]\n",
            " 14%|█▍        | 11/79 [00:00<00:00, 102.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For epoch 39 training loss is tensor(0.0318, grad_fn=<DivBackward0>)\n",
            "For epoch 39 training accuracy is tensor(0.9904)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:00<00:00, 104.66it/s]\n",
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy for narrow and deep network is tensor(0.9635)\n",
            "Test loss for narrow and deep network is tensor(0.1399, grad_fn=<DivBackward0>)\n",
            "Number of parameters for narrow and deep network 26432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}